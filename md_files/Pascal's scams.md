Beware of what I call Pascal's scams: movements or belief systems that ask you
to hope for or worry about very improbable outcomes that could have very large
positive or negative consequences. (The name comes of course from the
infinite-reward Wager proposed by Pascal: these days the large-but-finite
versions are far more pernicious).  Naive expected value reasoning implies
that they are worth the effort: if the odds are 1 in 1,000 that I could win $1
billion, and I am risk and time neutral, then I should expend up to nearly $1
million dollars worth of effort to gain this boon. The problems with these
beliefs tend to be at least threefold, all stemming from the general
uncertainty, i.e. the poor information or lack of information, from which we
abstracted the low probability estimate in the first place: because in the
messy real world the low probability estimate is almost always due to low or
poor evidence rather than being a lottery with well-defined odds:  
  
(1) there is usually no feasible way to distinguish between the very
improbable (say, 1 in 1,000) and the extremely improbable (e.g., one in a
billion). Poor evidence leads to what[ James
Franklin](http://lpr.oxfordjournals.org/content/5/2/159.full?keytype=ref&ijkey=ny8A8TF7Lp8kezF)
calls "low-weight probabilities", which lack robustness to new evidence. When
the evidence is poor, and thus robustness of probabilities is lacking, then it
is likely that "a small amount of further evidence would substantially change
the probability. "  This new evidence is as likely to decrease the probability
by a factor of X as increase it by a factor of X, and the poorer the original
evidence, the greater X is.  (Indeed, given the nature of human imagination
and bias, it is more likely to decrease it, for reasons described below).  
  
(2) the uncertainties about the diversity and magnitudes of possible
consequences, not just their probabilities, are also likely to be extremely
high. Indeed, due to the overall poor information, it's easy to overlook
negative consequences and recognize only positive ones, or vice-versa. The
very acts you take to make it into utopia or avoid dystopia could easily send
you to dystopia or make the dystopia worse.  
  
(3) The "unknown unknown" nature of the most uncertainty leads to
unfalsifiablity: proponents of the proposition can't propose a clear
experiment that would greatly lower the probability or magnitude of
consequences of their proposition: or at least, such an experiment would be
far too expensive to actually be run, or cannot be conducted until after the
time which the believers have already decided that the long-odds bet is
rational. So not only is there poor information in a Pascal scam, but in the
more pernicious beliefs there is little ability to improve the information.  
  
The biggest problem with these schemes is that, the closer to infinitesimal
probability, and thus usually to infinitesimal quality or quantity of
evidence, one gets, the closer to infinity the possible extreme-consequence
schemes one can dream up,  Once some enterprising memetic innovator dreams up
a Pascal's scam, the probabilities or consequences of these possible futures
can be greatly exaggerated yet still seem plausible. "Yes, but _what if_?" the
carrier of such a mind-virus incessantly demands.  Furthermore, since more
than a few disasters are indeed low probability events (e.g. 9/11), the
plausibility and importance of dealing with such risks seems to grow in
importance after they occur -- the occurrence of one improbable disaster leads
to paranoia about a large number of others, and similarly for fortuitous
windfalls and hopes. Humanity can dream up a near-infinity of Pascal's scams,
or spend a near-infinity of time fruitlessly worrying about them or hoping for
them. There are however far better ways to spend one's time -- for example in
thinking about what has actually happened in the real world, rather than the
vast number of things that might happen in the future but quite probably
won't, or will likely cause consequences very differently than you expect.  
  
So how should we approach low probability hypotheses with potential high value
(negative or positive) outcomes?  Franklin et. al.
[suggest](http://web.maths.unsw.edu.au/~jim/advocacydivdist.pdf) that "[t]he
strongly quantitative style of education in statistics, valuable as it is, can
lead to a neglect of the more qualitative, logical, legal and causal
perspectives needed to understand data intelligently. That is especially so in
extreme risk analysis, where there is a lack of large data sets to ground
solidly quantitative conclusions, and correspondingly a need to supplement the
data with outside information and with argument on individual data points."  
  
On the above quoted points I agree with Franklin, and add a more blunt
suggestion: stop throwing around long odds and dreaming of big consequences as
if you are onto something profound.  If you can't gather the information
needed to reduce the uncertainties, and if you can't suggest experiments to
make the hope or worry falsifiable, stop nightmaring or daydreaming already.
Also, shut up and stop trying to convince the rest of us to join you in
wasting our time hoping or worrying about these fantasies.  Try spending more
time learning about what has actually happened in the real world.  That study,
too, has its uncertainties, but they are up to infinitely smaller.  
  

